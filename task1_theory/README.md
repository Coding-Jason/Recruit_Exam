### **第一部分：理论理解题**

**背景:** 在动手之前，我们希望你对RoboMaster视觉组的工作和相关技术有一个基本的认识。

**任务:** 请仔细阅读[**《了解CV和RoboMaster视觉组》**](https://github.com/NeoZng/vision_tutorial/blob/main/了解CV和RoboMaster视觉组.md)文档，并根据你的理解回答以下问题（请将答案写在`task1_theory/README.md`中）：

1. 文档中提到了“小陀螺”是赛场上的一种经典战术，请简述它为什么会给传统的自瞄算法带来巨大挑战？

   答：

   1. **自瞄很难跟上装甲板的高速转动，**我方机器人的云台运动可能会滞后；即使使用预测算法，由于装甲板运动速度快，往往会导致预测失误，瞄到空气。

   2. 云台在切换跟踪高速旋转的装甲板的过程中会来回转动，无法稳定，弹丸命中率低。
   3. 操作手的第一界面不断晃动带来晕眩感，操纵体验极差。
   4. 英雄机器人开火冷却时间长、弹丸价格高昂，无法通过“火力覆盖”的方法凭借运气击中“小陀螺”。

   

2. 在使用传统视觉方法识别装甲板时，文档中提到通常需要**降低相机曝光**。请结合你自己的理解，解释为什么低曝光设置对提取亮着的灯条特征更有利？

   答：

   ![img](https://github.com/NeoZng/vision_tutorial/raw/main/Image_base/zoominHero.png)

   > p1 放大图像查看细节，发现灯条确实呈现白色

   1. 如p1所示，由于相机曝光过高，原本发出的蓝光饱和后，环境中微弱的红光和绿光也趋于饱和，导致颜色变白，不利于实战中颜色的识别。

   ![img](https://github.com/NeoZng/vision_tutorial/raw/main/Image_base/armorlowexposure.jpg)

   > p2 降低相机曝光后拍摄得到的图像，装甲板灯条显现纯粹的红色，杂光也大大降低了 我们在下面的步骤中就以这张图片为例简化过程分析，同时也不失一般性

   2. 如p2所示，降低曝光后可以很轻易地分辨出装甲板灯条的红色，同时降低曝光还能减少杂光的影响，进一步减少预处理的时间和复杂度。

   

3. 文档花了很多篇幅介绍为什么视觉开发推荐使用 **Ubuntu (Linux)** 系统而不是Windows，请总结一下作者给出的至少三个主要理由。

   答：

   1. **易安装与社区支持**：Ubuntu 安装简单，且有活跃的社区提供解决方案。
   2. **更优的资源管理与性能**：Ubuntu 占用更少系统资源，能更充分利用计算机性能。
   3. **便捷的开发环境配置**：通过包管理工具（如 `apt`）和 `cmake`，轻松管理第三方库和依赖。
   4. **深度学习与驱动支持**：Linux 对深度学习和设备驱动支持更完善，能精简内核并增加实时性补丁。

   

4. 请用你自己的话，简要描述**图像分类 (Image Classification)** 和**目标检测 (Object Detection)** 这两个任务的核心区别是什么？

   答：图像分类和目标检测的主要区别在于**任务的目标**和**输出内容**。

   1. 图像分类的任务是对整张图像进行分析，输出图像所属的类别，相对而言更简单；而目标检测不仅需要识别图像中的物体类别，还需要确定每个物体在图像中的位置。

   2. 图像分类的输出是一个类别标签，而目标检测的输出则包含多个物体的类别标签以及它们的边界框坐标。

   

5. 文档提到，由于镜头制造工艺等原因，相机会产生“畸变”（Distortion）。请用你自己的话简单描述什么是图像畸变，以及为什么在进行精确测量前，我们需要对相机进行标定（Calibration）？

   答：

   1. 图像畸变：由于凸透镜**本身的性质**和镜头制造的**工艺问题**，光线通过凸透镜时无法保持物体在空间中原本的位置关系。畸变主要分为切向畸变和桶型畸变。
   2. 通过标定，可以获取相机的**焦距、光心位置和畸变系数**等，从而将畸变影响修正掉。

   

6. `solvePnP`是视觉组进行位姿估计的核心函数之一。

   请阐述：`solvePnP`函数的主要作用是什么？谈谈自己对于PnP的理解。

   答：

   1. `solvePnP`函数的主要作用是通过已知的3D点和它们在图像中的2D投影，来估算相机的姿态和位置，通过已知的物体点的3D坐标和这些点在图像中的2D坐标，计算出相机相对于这些物体的位置和朝向。由于相机拍摄到的是2D图像，而实际操作中需要的是3D空间的位姿信息，`solvePnP`可以通过解算透视投影模型，从3D到2D的映射反向推算出相机的位姿——即相机的旋转角度和平移位置。

   2. `solvePnP`在计算机视觉领域具有重要地位，通过分析3D点和它们在图像中的2D投影，`solvePnP`可以推导出相机的具体位置和姿态。`solvePnP`广泛应用于增强现实、机器人导航、自动驾驶等任务中。通过提供准确的位姿估计，`solvePnP`帮助开发者快速实现与相机相关的定位和跟踪功能，推动了计算机视觉技术的普及和发展。它支持多种求解方法，具有很高的灵活性和实用性，是OpenCV库中不可或缺的工具之一。

   

7. 卡尔曼滤波器。

   请阐述：为什么在进行目标运动预测时，需要使用卡尔曼滤波器这类工具，而不是简单地用两帧之间的位置差来计算速度？它在机器人运动预测任务中主要解决了什么问题？

   答：
   
   1. 卡尔曼滤波器能有效地减少观测数据时**噪声的影响**，预测更准确。卡尔曼滤波器考虑了目标的速度、加速度用来构建**运动模型**，利用历史信息可做出更合理的预测。**多观测融合**比依赖两帧位置差要更精确。**平滑性和稳定性**：卡尔曼滤波器能减少因目标快速运动导致的预测波动。
   2. 通过使用卡尔曼模型，可以解决观测过程中的**噪声和不确定性**、**动态运动预测**、**多传感器数据融合**、**实时性要求。
   
   
